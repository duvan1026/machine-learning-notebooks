{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de contenidos\n",
    "* [<font color='blue'> ÁRBOLES DE CLASIFICACIÓN </font>](#<font-color='blue'>-ÁRBOLES-DE-CLASIFICACIÓN-</font>)\n",
    "\t* [<font color='blue'> Objetivo  </font>](#<font-color='blue'>-Objetivo--</font>)\n",
    "\t* [<font color='blue'> Árboles de decisión </font>](#<font-color='blue'>-Árboles-de-decisión-</font>)\n",
    "\t\t* [Definición](#Definición)\n",
    "\t\t* [Algoritmos para la construcción de árboles](#Algoritmos-para-la-construcción-de-árboles)\n",
    "\t\t* [ID3](#ID3)\n",
    "\t\t* [C4.5](#C4.5)\n",
    "\t\t* [Poda](#Poda)\n",
    "\t\t* [Reglas de clasificación](#Reglas-de-clasificación)\n",
    "\t* [<font color='blue'> Árboles de decisión en Python </font>](#<font-color='blue'>-Árboles-de-decisión-en-Python-</font>)\n",
    "\t\t* [Importar las librerías](#Importar-las-librerías)\n",
    "\t\t* [Importar el conjunto de datos](#Importar-el-conjunto-de-datos)\n",
    "\t\t* [Generar subconjuntos de entrenamiento y test](#Generar-subconjuntos-de-entrenamiento-y-test)\n",
    "\t\t* [Construir el modelo de árboles](#Construir-el-modelo-de-árboles)\n",
    "\t\t* [Evaluar el modelo](#Evaluar-el-modelo)\n",
    "\t\t* [Clasificar nuevos ejemplos](#Clasificar-nuevos-ejemplos)\n",
    "\t* [<font color='blue'> Conclusiones </font>](#<font-color='blue'>-Conclusiones-</font>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> ÁRBOLES DE CLASIFICACIÓN </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Objetivo  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción y uso del algoritmo de clasificación:\n",
    "\n",
    " * Árboles de decisión (algoritmos ID3 y C4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='blue'> Árboles de decisión </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un árbol de decisión es un conjunto de condiciones organizadas en una estructura jerárquica, de tal manera que la decisión final a tomar se puede determinar siguiendo las condiciones que se cumplen desde la raíz del árbol hasta alguna de sus hojas.\n",
    "\n",
    "Cada rama está etiquetada con un par atributo-valor y las hojas con una clase.\n",
    "\n",
    "<img src=\"../Figuras/ArbolGen.png\" alt=\"kmeans1\" width=\"200\"/> \n",
    "\n",
    "En el árbol de decisión, cada nodo interno representa un atributo, cada rama representa el valor del atributo y cada nodo hoja representa una etiqueta de clase (decisión final).\n",
    "\n",
    "La decisión final se determina siguiendo las condiciones satisfechas desde la raíz del árbol hasta algunas de sus hojas.\n",
    "\n",
    "Los caminos desde la raíz hasta la hoja representan reglas de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos para la construcción de árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **CLS** (Hunt et al., 1966)\n",
    "* **ID3** (Quinlan, 1979)\n",
    "* **CART** (Breiman et al., 1984) (Regresión)\n",
    "* **ACLS** (Niblett et al., 1982)\n",
    "* **ASSISTANT** (Cestnik et al., 1987)\n",
    "* **C4.5** (Quinlan, 1993)\n",
    "* ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Simple, pero potente.\n",
    "* Solo para atributos categóricos.\n",
    "* Estrategia de búsqueda voraz (greedy) por el espacio de posibles árboles de clasificación.\n",
    "* Proceso de creación del árbol (se construye de arriba hacia abajo):\n",
    "    * Seleccionar el mejor atributo como raíz del árbol.\n",
    "    * Crear una rama con cada uno de los posibles valores de dicho atributo.\n",
    "    * Repetir el proceso por cada rama hasta que los ejemplos se clasifiquen a través de uno de los caminos del árbol o se hayan usado todos los atributos.\n",
    "    * Cada nodo hoja se etiqueta con la clase de los ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo seleccionar el mejor atributo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cuestión es seleccionar el atributo que mejor separe los ejemplos de acuerdo a las clases. Para ello, habrá que usar la entropía (medida de incertidumbre).\n",
    "\n",
    "A menor valor de entropía, menor será la incertidumbre $\\Rightarrow$ más útil es el atributo para la clasificación.\n",
    "\n",
    "**Definición** de **entropía** en la teoría de la información (Shannon): <br>\n",
    "\n",
    "Dado un conjunto de eventos $A$ = {$A_1, A_2, \\dots{}, A_n$}, con probabilidades {$p_1, p_2, \\dots{},p_n$}, la información en el conocimiento de un suceso $A_i$ se define:\n",
    "\n",
    "$$ I(A_i) = \\log_{2}\\left(\\frac{1}{p_i}\\right) = -\\log_2(p_i)$$\n",
    "\n",
    "y la información media de A se define:\n",
    "\n",
    "$$ I(A) = \\sum_{i = 1}^{n}p_iI(A_i) = -\\sum_{i = 1}^{n}p_i\\log_2(p_i) = Entropía \\,(incertidumbre) $$\n",
    "\n",
    "Se puede medir lo que se discrimina usando un atributo $A_i$ empleando para ello la ganancia de información:\n",
    "\n",
    "$$ G(A_i) = I - I(A_i) $$\n",
    "\n",
    "Donde $I$ es la información antes de usar el atributo\n",
    "      e $I(A_i)$ la información después de usar el atributo.\n",
    "\n",
    "Como definición intuitiva, podemos decir que es la diferencia entre la entropía de un nodo y la de uno de sus descendientes.\n",
    "\n",
    "\n",
    "$$ I = -\\sum_{c=1}^{nc}\\frac{n_c}{n}\\log_{2}\\left(\\frac{n_c}{n}\\right)$$\n",
    "\n",
    "Donde:\n",
    "* **$nc$** es el número de clases\n",
    "* **$n$** es el número total de ejemplos.\n",
    "* **$n_c$** es el número de ejemplos de la clase c\n",
    "\n",
    "$$ I(A_i) = \\sum_{j = 1}^{nv(A_i)}\\frac{n_{ij}}{n}I_{ij}  \\,\\, ; \\,\\, I_{ij} = -\\sum_{k = 1}^{nc}\\frac{n_{ijk}}{n_{ij}}\\log_{2}\\left(\\frac{n_{ijk}}{n_{ij}}\\right)  $$\n",
    "\n",
    "Siendo:\n",
    "* **$nv(A_i)$** es el número de valores diferentes que toma el atributo **$A_i$**\n",
    "* **$n_{ij}$** es el número de ejemplos con el valor $j$ en el atributo **$A_i$**\n",
    "* **$n_{ijk}$** es el número de ejemplos con el valor $j$ en el atributo $A_i$ y que pertenecen a la clase $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algoritmo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Seleccionar el atributo $A_i$ que maximice la ganancia $G(A_i)$.\n",
    "2. Crear un nodo para ese atributo con tantos sucesores como valores diferentes tenga.\n",
    "3. Introducir los ejemplos en los sucesores según el valor que tenga en el atributo $A_i$.\n",
    "4. Por cada sucesor:\n",
    "    1. Si solo hay ejemplos de una clase, $C_k$, entonces etiquetarlo con $C_k$.\n",
    "    2. Si no, ir al paso 1 con una tabla formada por los ejemplos de ese nodo, eliminando la columna del atributo $A_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificar, haciendo uso del algoritmo ID3, los ejemplos de la siguiente tabla:\n",
    "\n",
    "\n",
    "| Outlook | Temperature | Humidity | Windy | play |\n",
    "|----------|-------------|----------|-------|------|\n",
    "| sunny | hot | high | FALSE | no |\n",
    "| sunny | hot | high | TRUE | no |\n",
    "| overcast | hot | high | FALSE | yes |\n",
    "| rainy | mild | high | FALSE | yes |\n",
    "| rainy | cool | normal | FALSE | yes |\n",
    "| rainy | cool | normal | TRUE | no |\n",
    "| overcast | cool | normal | TRUE | yes |\n",
    "| sunny | mild | high | FALSE | no |\n",
    "| sunny | cool | normal | FALSE | yes |\n",
    "| rainy | mild | normal | FALSE | yes |\n",
    "| sunny | mild | normal | TRUE | yes |\n",
    "| overcast | mild | high | TRUE | yes |\n",
    "| overcast | hot | normal | FALSE | yes |\n",
    "| rainy | mild | high | TRUE | no |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$ I = -\\frac{5}{14}\\log_{2}\\left(\\frac{5}{14}\\right)-\\frac{9}{14}\\log_{2}\\left(\\frac{9}{14}\\right) = 0.9403$$\n",
    "$$I_{outlook = sunny} = -\\frac{3}{5}\\log_{2}\\left(\\frac{3}{5}\\right)-\\frac{2}{5}\\log_{2}\\left(\\frac{2}{5}\\right) = 0.9710$$\n",
    "$$  I_{outlook = overcast} = -\\frac{4}{4}\\log_{2}\\left(\\frac{4}{4}\\right)-\\frac{0}{4}\\log_{2}\\left(\\frac{0}{4}\\right) = 0 $$\n",
    "$$ I_{outlook = rainy} = -\\frac{3}{5}\\log_{2}\\left(\\frac{3}{5}\\right)-\\frac{2}{5}\\log_{2}\\left(\\frac{2}{5}\\right) = 0.9710 $$\n",
    "$$I_{outlook} = \\frac{5}{14}I_{sunny} + \\frac{4}{14}I_{overcast} + \\frac{5}{14}I_{rainy} = 0.6936$$\n",
    "$$G_{outlook} = I - I_{outlook} = 0.9403 - 0.6936 = 0.2774 $$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$ I_{temperature = hot} = -\\frac{2}{4}\\log_{2}\\left(\\frac{2}{4}\\right)-\\frac{2}{4}\\log_{2}\\left(\\frac{2}{4}\\right) = 1$$\n",
    "$$I_{temperature = mild} = -\\frac{4}{6}\\log_{2}\\left(\\frac{4}{6}\\right)-\\frac{2}{6}\\log_{2}\\left(\\frac{2}{6}\\right) = 0.9183$$\n",
    "$$  I_{temperature = cool} = -\\frac{3}{4}\\log_{2}\\left(\\frac{3}{4}\\right)-\\frac{1}{4}\\log_{2}\\left(\\frac{1}{4}\\right) = 0.8113 $$\n",
    "$$I_{temperature} = \\frac{4}{14}I_{hot} + \\frac{6}{14}I_{mild} + \\frac{4}{14}I_{cool} = 0.9111$$\n",
    "$$G_{temperature} = I - I_{temperature} = 0.9403 - 0.9111 = 0.0292 $$\n",
    " \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$ I_{humidity = high} = -\\frac{3}{7}\\log_{2}\\left(\\frac{3}{7}\\right)-\\frac{4}{7}\\log_{2}\\left(\\frac{4}{7}\\right) = 0.9852$$\n",
    "$$I_{humidity = normal} = -\\frac{6}{7}\\log_{2}\\left(\\frac{6}{7}\\right)-\\frac{1}{7}\\log_{2}\\left(\\frac{1}{7}\\right) = 0.5917$$\n",
    "$$I_{humidity} = \\frac{7}{14}I_{high} + \\frac{7}{14}I_{normal} = 0.7884$$\n",
    "$$G_{humidity} = I - I_{humidity} = 0.9403 - 0.7884 = 0.1519 $$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$ I_{windy = true} = -\\frac{3}{6}\\log_{2}\\left(\\frac{3}{6}\\right)-\\frac{3}{6}\\log_{2}\\left(\\frac{3}{6}\\right) = 1$$\n",
    "$$I_{windy = false} = -\\frac{6}{8}\\log_{2}\\left(\\frac{6}{8}\\right)-\\frac{2}{8}\\log_{2}\\left(\\frac{2}{8}\\right) = 0.8113$$\n",
    "$$I_{windy} = \\frac{6}{14}I_{true} + \\frac{8}{14}I_{false} = 0.8922$$\n",
    "$$G_{windy} = I - I_{windy} = 0.9403 - 0.8922 = 0.0481 $$\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "El atributo *Outlook* maximiza la ganancia, por lo que se utiliza como nodo raíz del árbol de decisión:\n",
    "\n",
    "<img src=\"../Figuras/ID3-1.png\" alt=\"SubarbolSunny\" width=\"300\"/>\n",
    "\n",
    "Todos los ejemplos con *Outlook = Overcast* son positivos $\\Rightarrow$ Se convierte en nodo hoja.\n",
    "\n",
    "El resto tienen entropía no cero, se continúa el árbol.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Para construir el subárbol de la rama etiquetada como _sunny_, se eliminan las siguientes filas y columnas:\n",
    "\n",
    "<img src=\"../Figuras/TablaID3-1.png\" alt=\"TablaSunny\" width=\"400\"/>\n",
    "\n",
    "\n",
    "Se obtiene la siguiente tabla:\n",
    "\n",
    "| Temperature | Humidity | Windy | play |\n",
    "|:-----------:|:--------:|:-----:|:----:|\n",
    "| hot | high | FALSE | no |\n",
    "| hot | high | TRUE | no |\n",
    "| mild | high | FALSE | no |\n",
    "| cool | normal | FALSE | yes |\n",
    "| mild | normal | TRUE | yes |\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "$$ I = -\\frac{2}{5}\\log_{2}\\left(\\frac{2}{5}\\right)-\\frac{3}{5}\\log_{2}\\left(\\frac{3}{5}\\right) = 0.9710$$\n",
    "$$I_{temperature = hot} = -\\frac{0}{2}\\log_{2}\\left(\\frac{0}{2}\\right)-\\frac{2}{2}\\log_{2}\\left(\\frac{2}{2}\\right) = 0$$\n",
    "$$  I_{temperature = mild} = -\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right)-\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right) = 1 $$\n",
    "$$ I_{temperature = cool} = -\\frac{1}{1}\\log_{2}\\left(\\frac{1}{1}\\right)-\\frac{0}{1}\\log_{2}\\left(\\frac{0}{1}\\right) = 0 $$\n",
    "$$I_{temperature} = \\frac{2}{5}I_{hot} + \\frac{1}{5}I_{mild} + \\frac{2}{5}I_{cool} = 0.2$$\n",
    "$$G_{temperature} = I - I_{temperature} = 0.9710 - 0.2 = 0.7710 $$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$ I_{humidity = high} = -\\frac{0}{3}\\log_{2}\\left(\\frac{0}{3}\\right)-\\frac{3}{3}\\log_{2}\\left(\\frac{3}{3}\\right) = 0$$\n",
    "$$I_{humidity = normal} = -\\frac{2}{2}\\log_{2}\\left(\\frac{2}{2}\\right)-\\frac{0}{2}\\log_{2}\\left(\\frac{0}{2}\\right) = 0$$\n",
    "$$I_{humidity} = \\frac{3}{5}I_{high} + \\frac{2}{5}I_{normal} = 0$$\n",
    "$$G_{humidity} = I - I_{humidity} = 0.9710 - 0 = 0.9710 $$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$ I_{windy = true} = -\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right)-\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right) = 1$$\n",
    "$$I_{windy = false} = -\\frac{1}{3}\\log_{2}\\left(\\frac{1}{3}\\right)-\\frac{2}{3}\\log_{2}\\left(\\frac{2}{3}\\right) = 0.9183$$\n",
    "$$I_{windy} = \\frac{2}{5}I_{true} + \\frac{3}{5}I_{false} = 0.9510$$\n",
    "$$G_{windy} = I - I_{windy} = 0.9710 - 0.9510 = 0.02 $$\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "El atributo *Humidity* maximiza la ganancia, por lo que se utiliza como nodo hijo de la rama etiquetada como sunny:\n",
    "\n",
    "<img src=\"../Figuras/ID3-2.png\" alt=\"SubarbolHumidity\" width=\"300\"/>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Para construir el subárbol de la rama etiquetada como rainy, se eliminan las siguientes filas y columnas:\n",
    "\n",
    "<img src=\"../Figuras/TablaID3-2.png\" alt=\"TablaHumidity\" width=\"400\"/>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "Se obtiene la siguiente tabla:\n",
    "\n",
    "| Temperature | Humidity | Windy | play |\n",
    "|:-----------:|:--------:|:-----:|:----:|\n",
    "| mild | high | FALSE | yes |\n",
    "| cool | normal | FALSE | yes |\n",
    "| cool | normal | TRUE | no |\n",
    "| mild | normal | FALSE | yes |\n",
    "| mild | high | TRUE | no |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$ I = -\\frac{3}{5}\\log_{2}\\left(\\frac{3}{5}\\right)-\\frac{2}{5}\\log_{2}\\left(\\frac{2}{5}\\right) = 0.9710$$\n",
    "$$I_{temperature = hot} = -\\frac{0}{0}\\log_{2}\\left(\\frac{0}{0}\\right)-\\frac{0}{0}\\log_{2}\\left(\\frac{0}{0}\\right) = ?$$\n",
    "$$  I_{temperature = mild} = -\\frac{2}{3}\\log_{2}\\left(\\frac{2}{3}\\right)-\\frac{1}{3}\\log_{2}\\left(\\frac{1}{3}\\right) = 0.9183 $$\n",
    "$$ I_{temperature = cool} = -\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right)-\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right) = 1 $$\n",
    "$$I_{temperature} = \\frac{0}{5}I_{hot} + \\frac{3}{5}I_{mild} + \\frac{2}{5}I_{cool} = 0.9510$$\n",
    "$$G_{temperature} = I - I_{temperature} = 0.9710 - 0.9510 = 0.02 $$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$ I_{humidity = high} = -\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right)-\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right) = 1$$\n",
    "$$I_{humidity = normal} = -\\frac{2}{3}\\log_{2}\\left(\\frac{2}{3}\\right)-\\frac{1}{3}\\log_{2}\\left(\\frac{1}{3}\\right) = 0.9183$$\n",
    "$$I_{humidity} = \\frac{2}{5}I_{high} + \\frac{3}{5}I_{normal} = 0.9510$$\n",
    "$$G_{humidity} = I - I_{humidity} = 0.9710 - 0.9510 = 0.02 $$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "$$ I_{windy = true} = -\\frac{0}{2}\\log_{2}\\left(\\frac{0}{2}\\right)-\\frac{2}{2}\\log_{2}\\left(\\frac{2}{2}\\right) = 0$$\n",
    "$$I_{windy = false} = -\\frac{3}{3}\\log_{2}\\left(\\frac{3}{3}\\right)-\\frac{0}{3}\\log_{2}\\left(\\frac{0}{3}\\right) = 0$$\n",
    "$$I_{windy} = \\frac{2}{5}I_{true} + \\frac{3}{5}I_{false} = 0$$\n",
    "$$G_{windy} = I - I_{windy} = 0.9710 - 0 = 0.9710 $$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "El atributo *Windy* maximiza la ganancia, por lo que se utiliza como nodo hijo de la rama etiquetada como *rainy*:\n",
    "\n",
    "<img src=\"../Figuras/ID3-3.png\" alt=\"ArbolCompleto\" width=\"300\"/>\n",
    "\n",
    "\n",
    "\n",
    "De esta manera se obtiene el árbol completo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maneja atributos categóricos y continuos\n",
    "* Hace uso del concepto de razón de ganancia (GR - Gain Ratio)\n",
    "* Permite la existencia de valores desconocidos.\n",
    "* Poda de ramas del árbol de decisión\n",
    "* Obtiene de reglas de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Razón de ganancia (GR - Gain Ratio)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se seleccionan los atributos usando la ratio de ganancia $\\Rightarrow$ Maximizar la ganancia.\n",
    "\n",
    "\n",
    "$$GR(A_i) = \\frac{G(A_i)}{I(División \\, A_i)} = \\frac{G(A_i)}{-\\sum_{j = 1}^{nv(A_i)} \\frac{n_{ij}}{n}\\log_{2}\\left(\\frac{n_{ij}}{n}\\right)}$$\n",
    "\n",
    "Donde a $I(División \\, A_i)$ también se le denomina **Información de ruptura**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valores desconocidos (missing values)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eliminar instancias incompletas\n",
    "* Estimar dichos valores (imputación):\n",
    "    * Asignarles la moda de los ejemplos asociados al nodo que se esté calculando o de los ejemplos del nodo que tienen la misma etiqueta que la instancia a imputar.\n",
    "    * Asignar distribución de probabilidad de cada posible valor del atributo, estimada con las frecuencias observadas en el nodo, y son las que se distribuyen por el árbol y con las que se calcula la ganancia.\n",
    "* Se redefinen los términos:<br>\n",
    "&nbsp;&nbsp;$G(A_i) = \\frac{n_{ic}}{n}(I - I(A_i))$<br>\n",
    "&nbsp;&nbsp;$I(División \\,\\, A_i) = -\\left(  \\sum_{j=1}^{nv(A_i)} \\frac{n_{ij}}{n}\\log_{2}\\left(\\frac{n_{ij}}{n}\\right)\\right) - \\frac{n_{id}}{n}\\log_{2}\\left(\\frac{n_{id}}{n}\\right)$ <br>\n",
    "    * Donde $n_{ic}$ es el nº de ejemplos con el atributo $i$ conocido.\n",
    "    * Donde $n_{id}$ es el nº de ejemplos con el atributo $i$ desconocido.\n",
    "    \n",
    "Nota: para el cálculo de las entropía $I(A_i)$ se consideran únicamente los ejemplos en los que el atributo $A_i$ no sea desconocido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discretización de atributos continuos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se ordenan los valores del atributo.\n",
    "* Se busca un punto entre cada par de valores que produzca la máxima ganancia de información, permitiendo dividir los valores en dos subconjuntos.\n",
    "* Algunas reglas para no estudiar todos los posibles puntos de corte:\n",
    "    * Establecer un número mínimo de ejemplos para cada subintervalo.\n",
    "    * No dividir el intervalo si el siguiente ejemplo pertenece a la misma clase.\n",
    "    * Unir subintervalos adyacentes si tienen la misma clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La poda del árbol se propone como solución al problema de controlar el crecimiento del árbol, evitando el sobreajuste y árboles de gran complejidad.\n",
    "Existen 2 tipos:\n",
    "* **Pre-poda:** poda y construcción del árbol de forma simultánea. Deja de aumentar el árbol antes de que alcance el punto en el que clasifica perfectamente los ejemplos de entrenamiento. <br>\n",
    "Problema: complicado estimar cuándo se produce.\n",
    "    * Se aplica un test estadístico para estimar si expandiendo un nodo particular es probable producir una mejora.\n",
    "* **Post-poda:** poda después de haber creado el árbol. Permite que se produzca un sobreajuste de los datos, y después realiza la poda reemplazando subárboles por una hoja. <br>\n",
    "En la práctica es más adecuada, pero es más costoso computacionalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Post-poda**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La poda comienza en los nodos hoja y continúa hasta llegar al nodo raíz.\n",
    "Dos operaciones:\n",
    "* **subtree replacement:** reemplazo de un subárbol por una hoja, asignándole la clasificación más común de los ejemplos de entrenamiento asociados a ese nodo.\n",
    "* **subtree raising**: elevación de un subárbol $\\Rightarrow$ reclasificar de nuevo los ejemplos. <br>\n",
    "Muy costoso computacionalmente $\\Rightarrow$ restringir su uso al camino más largo a partir del nodo que estamos podando.\n",
    "\n",
    "> * Se poda solo si el árbol podado resultante mejora o iguala el rendimiento del árbol original sobre el conjunto de prueba.\n",
    "> * Realizar la poda iterativamente, escogiendo siempre el nodo a podar que mejore más la precisión en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reglas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Estructura: <br>\n",
    "&nbsp; SI <condición> ENTONCES <clase\\>\n",
    "* Proceso:\n",
    "    * Para cada rama del árbol:\n",
    "        * Las preguntas y sus valores a la parte izquierda de la regla (Antecedente)\n",
    "        * La etiqueta del nodo hoja en la parte derecha (Consequente)\n",
    "* Podado de las reglas para evitar un sistema de reglas muy complejo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Árboles de decisión en Python </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier    #Árbol de decisión para clasificación\n",
    "from sklearn.tree import plot_tree, export_graphviz, export_text\n",
    "from pydotplus import graph_from_dot_data\n",
    "\n",
    "\n",
    "# Gráficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Configuración warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"DataSets/Clima.csv\")\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las variables independientes y la variable respuesta\n",
    "X = data_train.drop('Play', axis=1) #Elimina la última columna, variable respuesta\n",
    "y = data_train['Play'] #Toma la última columna, variable respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el conjunto test, datos nuevos, para realizar las transformaciones sobre todos los datos\n",
    "test_real = pd.read_csv(\"DataSets/Ejemplo.csv\")\n",
    "print(test_real)\n",
    "\n",
    "# Obtener variables independientes\n",
    "test_real = test_real.drop('Play', axis=1) #Elimina la última columna, variable respuesta\n",
    "test_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar subconjuntos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding para Outlook y Humidity. Usamos get_dummies y OneHotEncoder para ver las diferencias.\n",
    "\n",
    "# Codificar 'Outlook' con get_dummies, aplicar sobre train y alinear test\n",
    "\n",
    "X_train_outlook = pd.get_dummies(\n",
    "    X_train[['Outlook']], prefix=\"Out\"\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "X_test_outlook = pd.get_dummies(\n",
    "    X_test[['Outlook']], prefix=\"Out\"\n",
    ").astype(int)\n",
    "\n",
    "test_real_outlook = pd.get_dummies(\n",
    "    test_real[['Outlook']], prefix=\"Out\"\n",
    ").astype(int)\n",
    "\n",
    "# Alinear columnas para que el conjunto de test tenga las mismas que train\n",
    "X_test_outlook = X_test_outlook.reindex(columns=X_train_outlook.columns, fill_value=0)\n",
    "test_real_outlook = test_real_outlook.reindex(columns=X_train_outlook.columns, fill_value=0)\n",
    "\n",
    "# Se puede incorporar el parámetro drop_first=True, lo que hace es eliminar la columna irrelevante, toda la información \n",
    "# se puede en una variable menos que el número de categorías.\n",
    "\n",
    "print(X_train_outlook)\n",
    "print(X_test_outlook)\n",
    "print(test_real_outlook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar 'Humidity' con OneHotEncoder \n",
    "\n",
    "cod_ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "cod_ohe.fit(X_train[['Humidity']])  # Sólo fit con train\n",
    "\n",
    "\n",
    "# Transformar train y test\n",
    "\n",
    "X_train_humidity = pd.DataFrame(\n",
    "    cod_ohe.transform(X_train[['Humidity']]),\n",
    "    columns=cod_ohe.get_feature_names_out(['Humidity']), # Nombres de las columnas codificadas\n",
    "    index=X_train.index\n",
    ").astype(int)\n",
    "\n",
    "X_test_humidity = pd.DataFrame(\n",
    "    cod_ohe.transform(X_test[['Humidity']]),\n",
    "    columns=cod_ohe.get_feature_names_out(['Humidity']), # Nombres de las columnas codificadas\n",
    "    index=X_test.index\n",
    ").astype(int)\n",
    "\n",
    "test_real_humidity = pd.DataFrame(\n",
    "    cod_ohe.transform(test_real[['Humidity']]),\n",
    "    columns=cod_ohe.get_feature_names_out(['Humidity']), # Nombres de las columnas codificadas\n",
    "    index=test_real.index\n",
    ").astype(int)\n",
    "\n",
    "print(X_train_humidity)\n",
    "print(X_test_humidity)\n",
    "print(test_real_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se podría haber usado LabelEncoder al conjunto completo si el modelo no es sensible al orden, como ocurre en un árbol.\n",
    "#data['Humidity'] = OrdinalEncoder(categories=[['normal','high']]).fit_transform(data['Humidity'].values.reshape((-1, 1)))\n",
    "#data['Humidity']\n",
    "\n",
    "# Pero como eso no ocurre para todos los modelos lo hacemos como deberíamos hacerlo en la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación binaria para Windy\n",
    "\n",
    "X_train_windy = X_train[['Windy']].astype(int)\n",
    "X_test_windy = X_test[['Windy']].astype(int)\n",
    "test_real_windy = test_real[['Windy']].astype(int)\n",
    "\n",
    "print(X_train_windy)\n",
    "print(X_test_windy)\n",
    "print(test_real_windy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar 'Temperature' ordinalmente\n",
    "\n",
    "# Una forma sencilla:\n",
    "#temp_map = {'cool': 0, 'mild': 1, 'hot': 2}\n",
    "#X_train_temp = X_train[['Temperature']].replace({'Temperature': temp_map})\n",
    "#X_test_temp = X_test[['Temperature']].replace({'Temperature': temp_map})\n",
    "\n",
    "\n",
    "# Codificar 'Temperature' según el orden: cool < mild < hot\n",
    "encoder_temp = OrdinalEncoder(categories=[['cool', 'mild', 'hot']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Codificar sobre train\n",
    "X_train_temp = X_train[['Temperature']].copy()\n",
    "X_train_temp['Temperature'] = encoder_temp.fit_transform(\n",
    "    X_train['Temperature'].values.reshape(-1, 1)\n",
    ").astype(int)\n",
    "\n",
    "# Codificar sobre test usando el mismo encoder (sin refit)\n",
    "X_test_temp = X_test[['Temperature']].copy()\n",
    "X_test_temp['Temperature'] = encoder_temp.transform(\n",
    "    X_test['Temperature'].values.reshape(-1, 1)\n",
    ").astype(int)\n",
    "\n",
    "test_real_temp = test_real[['Temperature']].copy()\n",
    "test_real_temp['Temperature'] = encoder_temp.transform(\n",
    "    test_real['Temperature'].values.reshape(-1, 1)\n",
    ").astype(int)\n",
    "\n",
    "print(X_train_temp)\n",
    "print(X_test_temp)\n",
    "print(test_real_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se codifica también la variable de salida\n",
    "y_play = LabelEncoder()\n",
    "y= y_play.fit_transform(y.values.reshape((-1, 1)))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todo\n",
    "\n",
    "X_train_final = pd.concat([\n",
    "    X_train_outlook.reset_index(drop=True),\n",
    "    X_train_temp.reset_index(drop=True),\n",
    "    X_train_humidity.reset_index(drop=True),\n",
    "    X_train_windy.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "X_test_final = pd.concat([\n",
    "    X_test_outlook.reset_index(drop=True),\n",
    "    X_test_temp.reset_index(drop=True),\n",
    "    X_test_humidity.reset_index(drop=True),\n",
    "    X_test_windy.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "test_real_final = pd.concat([\n",
    "    test_real_outlook.reset_index(drop=True),\n",
    "    test_real_temp.reset_index(drop=True),\n",
    "    test_real_humidity.reset_index(drop=True),\n",
    "    test_real_windy.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "# Mostrar resultados\n",
    "\n",
    "print(\"X_train codificado:\")\n",
    "print(X_train_final)\n",
    "\n",
    "print(\"\\nX_test codificado:\")\n",
    "print(X_test_final)\n",
    "\n",
    "print(\"\\nX_test codificado:\")\n",
    "print(test_real_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir el modelo de árboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la instancia de Árboles con los datos de entrenamiento\n",
    "arbol = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, random_state=42) #Árbol de profundidad 5\n",
    "\n",
    "# Realiza el entrenamiento usando el método fit\n",
    "arbol.fit(X_train_final, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observése qué ocurre si se obtiene la precisión sobre el mismo conjunto de entrenamiento\n",
    "score = arbol.score(X_train_final,y_train)\n",
    " \n",
    "print(\"Métrica del modelo para el conjunto de entrenamiento\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir la respuesta sobre un conjunto no usado durante el entrenamiento, conjunto test\n",
    "y_pred = arbol.predict(X_test_final)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los valores de las métricas\n",
    "print('Matriz de confusión: ')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('\\n\\nMétricas de clasificación:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar el modelo usando Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se fija el valor para k-folds\n",
    "kf = KFold(n_splits=6)\n",
    "\n",
    "scores = cross_val_score(arbol, X_train_final, y_train, cv=kf, scoring=\"accuracy\")\n",
    " \n",
    "print(\"Precisión obtenida para cada iteración de validación cruzada:\", scores)\n",
    " \n",
    "print(\"Media de la precisión obtenida en cada una de las iteraciones de validación cruzada:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede obtener más información midiendo el rendimiento usando cross_validate en vez de cross_val_score\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "scores = cross_validate(arbol, X_train_final, y_train, scoring=scoring, cv=kf, return_train_score=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred = accuracy_score(y_test, y_pred)\n",
    " \n",
    "print(\"Métrica en el conjunto test:\", score_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Matriz de confusión: ')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('\\n\\nMétricas de clasificación:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la figura\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "\n",
    "print(f\"Profundidad del árbol: {arboles.get_depth()}\")\n",
    "print(f\"Número de nodos terminales: {arboles.get_n_leaves()}\")\n",
    "\n",
    "# Dibujamos el árbol\n",
    "plot_tree(\n",
    "    decision_tree=arboles,\n",
    "    feature_names=list(X_train_final.columns),     \n",
    "    class_names=y_play.classes_.tolist(),          #['no', 'yes'] recuperado del LabelEncoder\n",
    "    filled=True,\n",
    "    impurity=False,\n",
    "    fontsize=10,\n",
    "    precision=2,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Mostramos\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reglas\n",
    "#------\n",
    "reglas = export_text(\n",
    "                    decision_tree = arboles,\n",
    "                    feature_names = list(X_train_final.columns)\n",
    "               )\n",
    "print(reglas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizar los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el valor obtenido de la precisión para el conjunto de prueba es del 50%, observaciones del conjunto de test son observaciones no usadas durante el entrenamiento. Un rendimiento muy pobre del modelo al clasificar datos desconocidos, no presenta una buena capacidad de generalización. \n",
    "\n",
    "Este comportamiento puede ser debido a un sobreajuste del modelo (_overfitting_), como consecuencia de la flexibilidad del método. Si el modelo no está generalizando bien habría que hacer un reajuste del modelo para evitarlo. Cuando se trata de un árbol grande una opción es realizar la poda del árbol. \n",
    "\n",
    "En este caso, lo que ocurre es que el árbol es muy pequeño, existen muy pocos datos en el conjunto de entrenamiento, lo que dificulta mucho el aprendizaje de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificar nuevos ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se alcance unos valores de las métricas que permitan aceptar el modelo como válido y que, por tanto, está listo para su uso, se llevaría a un entorno real y productivo. En esa situación el modelo se enfrentará a datos totalmente desconocidos, los datos almacenados sobre el conjunto test_real, y no se podrá evaluar la respuesta del modelo, salvo las indicaciones que puedan arrojar los expertos en la materia a partir del conocimiento del dominio del problema a resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica el modelo sobre datos desconocidos\n",
    "# Se aplica sobre el conjunto test_real\n",
    "res = arboles.predict(test_real_final)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Conclusiones </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha construido un modelo de clasificación Árboles de Decisión en lenguaje de programación Python. Los árboles son muy simples y fáciles de interpretar, se adaptan a cualquier tipo de dato y permiten descubrir cuáles son atributos relevantes. Presentan la desventaja de que tienden al sobreajuste, sobre todo si no se regularizan. La regularización se basa en utilizar determinadas restricciones sobre el modelo a entrenar para evitar que se produzca el sobreajuste.\n",
    "\n",
    "A partir del análisis de los resultados se puede observar si se trata de un buen modelo para poder ser utilizado en la resolución del problema planteado. En este ejemplo, en concreto, existen pocos datos, por lo que la precisión de la clasificación no es muy buena.\n",
    "\n",
    "Se pueden comparar los resultados con los obtenidos con el algoritmo Naïve Bayes.¿Difieren los resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\"/> \n",
    "\n",
    "Esta obra está bajo una Licencia Creative Commons Atribución-NoComercial-CompartirIgual 4.0 Internacional.\n",
    "Para ver una copia de esta licencia, véase http://creativecommons.org/licenses/by/4.0/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
