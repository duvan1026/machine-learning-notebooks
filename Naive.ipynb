{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de contenidos\n",
    "* [<font color='blue'> CLASIFICACIÓN NAÏVE BAYES </font>](#<font-color='blue'>-CLASIFICACIÓN-NAÏVE-BAYES-</font>)\n",
    "\t* [<font color='blue'> Objetivo </font>](#<font-color='blue'>-Objetivo-</font>)\n",
    "\t* [<font color='blue'> Clasificación bayesiana </font>](#<font-color='blue'>-Clasificación-bayesiana-</font>)\n",
    "\t\t* [La probabilidad condicionada P(A|B)](#La-probabilidad-condicionada-P%28A|B%29)\n",
    "\t\t* [Clasificador bayesiano](#Clasificador-bayesiano)\n",
    "\t\t* [Ejemplo 1](#Ejemplo-1)\n",
    "\t\t* [Ejemplo 2](#Ejemplo-2)\n",
    "\t\t* [Clasificador naïve (ingenuo) bayesiano](#Clasificador-naïve-%28ingenuo%29-bayesiano)\n",
    "\t\t* [Ejemplo](#Ejemplo)\n",
    "\t\t* [Comentarios finales](#Comentarios-finales)\n",
    "\t* [<font color='blue'> Algoritmo Naïve Bayes en Python</font>](#<font-color='blue'>-Algoritmo-Naïve-Bayes-en-Python</font>)\n",
    "\t\t* [Importar las librerías](#Importar-las-librerías)\n",
    "\t\t* [Importar el conjunto de datos](#Importar-el-conjunto-de-datos)\n",
    "\t\t* [Transformar los datos](#Transformar-los-datos)\n",
    "\t\t* [Generar subconjuntos de entrenamiento y validación](#Generar-subconjuntos-de-entrenamiento-y-validación)\n",
    "\t\t* [Construir el modelo NBC](#Construir-el-modelo-NBC)\n",
    "\t\t* [Evaluar el modelo](#Evaluar-el-modelo)\n",
    "\t\t* [Análisis de los resultados](#Análisis-de-los-resultados)\n",
    "\t\t* [Clasificar nuevos ejemplos](#Clasificar-nuevos-ejemplos)\n",
    "\t* [<font color='blue'> Conclusión </font>](#<font-color='blue'>-Conclusión-</font>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> CLASIFICACIÓN NAÏVE BAYES </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Objetivo </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción y uso del algoritmo de clasificación\n",
    "\n",
    " * Bayesiana (algoritmo Naïve Bayes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Clasificación bayesiana </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo Naïve Bayes es un clasificador probabilístico basado en modelos de probabilidad que incorporan fuertes supuestos de independencia. Los supuestos de independencia a menudo no tienen impacto en la realidad. Por lo tanto, son considerados como ingenuo.\n",
    " \n",
    "Los modelos de probabilidad se pueden obtener utilizando el __Teorema de Bayes__.\n",
    "\n",
    "El teorema bayesiano sostiene que la probabilidad de que ocurra un evento cambia si hay información disponible sobre un evento relacionado.\n",
    "\n",
    "Dependiendo de la naturaleza del modelo de probabilidad, el algoritmo Naïve Bayes se puede entrenar en un entorno de aprendizaje supervisado.\n",
    "\n",
    "Los clasificadores bayesianos pueden predecir las probabilidades de pertenencia a una clase, es decir, la probabilidad de que una tupla dada pertenezca a una clase particular.\n",
    "\n",
    "Usa los valores dados para entrenar un modelo y luego usa este modelo para clasificar nuevos datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La probabilidad condicionada P(A|B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expresa la probabilidad del suceso A condicionado a B. También es conocida como probabilidad a posteriori, mientras que P(A) es denominada probabilidad a priori.\n",
    "\n",
    "El suceso B ocurre con toda seguridad, por lo que se expresa la probabilidad de que A también ocurra. La probabilidad condicionada cumple la siguiente propiedad:\n",
    "\n",
    "$$ P(A\\,|\\,B) = P(A\\cap{}B) / {}P(B)$$\n",
    "$$ P(A\\cap{}B) = P(A\\,|\\,B)\\cdot{}P(B) = P(B\\,|\\,A)\\cdot{}P(A)$$\n",
    "\n",
    "\n",
    "$$ P(A|B) = P(B|A)\\cdot{}P(A) / {}P(B) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador bayesiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $A_1, A_2, \\ldots, A_n$ un conjunto de sucesos incompatibles 2 a 2 (conjunto de clases), con probabilidad distinta de cero. Y sea B un suceso cualquiera (nuevo patrón de entrada, evidencia), conocida $P(B\\,|\\,A_i)$, entonces la probabilidad  $P(A_i\\,|\\,B)$ viene dada por la expresión:\n",
    "\n",
    "$$P(A_i\\,|\\,B) = \\frac{P(B\\,|\\,A_i)P(A_i)}{P(B)} = \\frac{P(B\\,|\\,A_i)P(A_i)}{\\sum_{k = 1}^{n}P(B\\,|\\,A_k)P(A_k)}$$\n",
    "\n",
    "**Donde...**\n",
    "* $P(A_i\\,|\\,B)$ es la probabilidad a posteriori.\n",
    "* $P(B\\,|\\,A_i)P(A_i)$ es la probabilidad condicional de B en la hipótesis $A_i$ (verosimilitudes)\n",
    "* $P(A_i)$ es la probabilidad a priori\n",
    "\n",
    "> Permite conocer, a partir de la probabilidad de una clase, la probabilidad de dicha clase una vez obtenido el patrón B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 20% de los empleados de una empresa son ingenieros y otro 20% son economistas. El 75% de los ingenieros ocupan un puesto directivo y el 50% de los economistas también, mientras que de los no ingenieros y los no economistas solamente el 20% ocupa un puesto directivo. ¿Cuál es la probabilidad de que un empleado directivo elegido al azar sea ingeniero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingeniero = Ingeniero\n",
    "# Economista = Economista\n",
    "# No Economista No Ingeniero = NENI\n",
    "# D = directivo\n",
    "\n",
    "pIngeniero = 0.2\n",
    "pEconomista = 0.2\n",
    "pNINE = 1 - pIngeniero - pEconomista\n",
    "print('La probabilidad de no ser ni ingeniero ni economista es: {0:.1f}'. format(pNINE))\n",
    "\n",
    "pDsiendoI = 0.75\n",
    "pDsiendoE = 0.5\n",
    "pDsiendoNINE = 0.2\n",
    "\n",
    "# Cálculo de P(Ingeniero | Directivo)\n",
    "\n",
    "pDeIngenieroSiendoDirectivo = (pIngeniero * pDsiendoI)/(  (pIngeniero * pDsiendoI) + (pEconomista * pDsiendoE) + (pNINE * pDsiendoNINE))\n",
    "print('La probabilidad de que sea directivo un empleado es: {0:.3f}'. format(pDeIngenieroSiendoDirectivo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de que haya un accidente en una fábrica que dispone de alarma es 0.1. La probabilidad de que suene ésta si se ha producido algún incidente es de 0.97 y la probabilidad de que suene si no ha sucedido ningún incidente es 0.02.\n",
    "En el supuesto de que haya funcionado la alarma, ¿cuál es la probabilidad de que no haya habido ningún incidente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se recomienda realizar el ejercicio antes de comprobar la solución\n",
    "\n",
    "# Accidente/Incidente = I\n",
    "# Suena la alarma/funciona la alarma = SA\n",
    "\n",
    "pI = 0.1\n",
    "print('Probabilidad de producirse incidente: {0:.2}'. format(pI))\n",
    "pSAcuandoI = 0.97\n",
    "print('Probabilidad de que suene la alarma si se ha producido incidente: {0:.2}'. format(pSAcuandoI))\n",
    "pNotSAcuandoI = 1-pSAcuandoI\n",
    "print('Probabilidad de que no suene la alarma si se ha producido incidente: {0:.2}'. format(pNotSAcuandoI))\n",
    "\n",
    "pNotI= 1 - pI\n",
    "print('Probabilidad de no producirse incidente: {0:.2}'. format(pNotI))\n",
    "pSAcuandoNotI = 0.02\n",
    "print('Probabilidad de que suene la alarma si no se ha producido incidente: {0:.2}'. format(pSAcuandoNotI))\n",
    "pNotSAcuandoNotI = 1-pSAcuandoNotI\n",
    "print('Probabilidad de que no suene la alarma si no se ha producido incidente: {0:.2}'. format(pNotSAcuandoNotI))\n",
    "\n",
    "# Cálculo de P(NotI|SA)\n",
    "pNotIcuandoSA = (pNotI * pSAcuandoNotI)/((pI * pSAcuandoI) + (pNotI * pSAcuandoNotI))\n",
    "print('Probabilidad de que funcionando la alarma suene sin producirse ningún incidente: {0:.3f}'.format(pNotIcuandoSA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador naïve (ingenuo) bayesiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiendo entonces del Teorema de Bayes, en general:\n",
    "\n",
    "$$ P(h\\,|\\,D) = \\frac{P(D\\,|\\,h)P(h)}{P(D)}$$ \n",
    "\n",
    "__Donde:__\n",
    "\n",
    "- $P(h\\,|\\,D)$ es la probabilidad a posteriori de la hipótesis dados los datos\n",
    "- $P(D\\,|\\,h)$ es la probabilidad de los datos dada una hipótesis\n",
    "- $P(D)$ es la probabilidad a priori de los datos\n",
    "\n",
    "Se estima la hipótesis más probable (MAP-maximum a posteriori hipótesis)\n",
    "\n",
    "$$ h_{MAP} = argmax_{h \\in{} H} (P(h\\,|\\,D))$$\n",
    "\n",
    "$$ = argmax_{h \\in{} H} \\left(\\frac{P(D\\,|\\,h)P(h)}{P(D)}\\right) $$\n",
    "\n",
    "dado que P(D) es una constante independiente de h:\n",
    "\n",
    "$$ = argmax_{h \\in{} H} (P(D\\,|\\,h)P(h))$$\n",
    "\n",
    "Si asumimos que todas las hipótesis son igualmente probables, para cada probabilidad a posteriori solo queda la función de verosimilitud, entonces resulta la hipótesis de máxima verosimilitud (ML-maximum likelihood)\n",
    "\n",
    "$$ h_{ML} = argmax_{h \\in{} H} (P(D\\,|\\,h)) $$\n",
    "\n",
    "Si $D$ viene representado por un conjunto de atributos $a_i$ y $h$ corresponde a una clase $v_j \\in{} V$, para obtener la clase más probable en base a los valores de los atributos:\n",
    "\n",
    "$$ v_{MAP} = argmax_{v_{j} \\in{} V} \\left(P(v_{j}\\,|\\,a_1, \\cdots, a_n) \\right) $$\n",
    "\n",
    "$$ = argmax_{v_{j} \\in{} V} \\left(\\frac{P(a_1, \\cdots, a_n\\,|\\,v_j)P(v_j)}{P(a_1, \\cdots, a_n)}\\right) $$\n",
    "\n",
    "$$ = argmax_{v_{j} \\in{} V} \\left(P(a_1, \\cdots, a{n}\\,|\\,v_j)P(v_j)\\right)$$\n",
    "\n",
    "Como el clasificador naïve bayesiano supone que los valores de los atributos son condicionalmente independientes dado el valor de la clase (independencia condicional de la clase):\n",
    "\n",
    "$$ P(a_1, \\cdots, a{n}\\,|\\,v_j) = \\prod_{i} P(a_{i}\\,|\\,v_{j})$$\n",
    "por lo tanto:\n",
    "$$ P(v_j\\,|\\,a_1, \\cdots, a{n}) = P(v_{j})\\times{}\\prod_{i} P(a_{i}\\,|\\,v_{j})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"DataSets/Clima.csv\") \n",
    "\n",
    "data.head(len(data.index)) #Visualiza todas las filas del fichero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proceso de aprendizaje**\n",
    "\n",
    "<img src=\"../Figuras/TablaClima.png\" alt=\"tabla\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clasificación de un ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSets/Ejemplo.csv\")\n",
    "\n",
    "data.head(1) #Visualiza la única fila del fichero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(Yes\\,|\\,Sunny, Cool, High, True) = \\frac{9}{14}\\times{}\\frac{2}{9}\\times{}\\frac{3}{9}\\times{}\\frac{3}{9}\\times{}\\frac{3}{9} = 0.0053 $$\n",
    "\n",
    "$$ P(No\\,|\\,Sunny, Cool, High, True) = \\frac{5}{14}\\times{}\\frac{3}{5}\\times{}\\frac{1}{5}\\times{}\\frac{4}{5}\\times{}\\frac{3}{5} = 0.0206 $$\n",
    "\n",
    "Para la normalización de los resultados, hay que calcular el cociente de la probabilidad calculada entre la suma de la misma más la probabilidad del suceso opuesto.\n",
    "\n",
    "$$ P_{normalizado}(Yes\\,|\\,Sunny, Cool, High, True) = \\frac{0.0053}{0.0053 + 0.0206}\\times{} 100 = 20.5$$\n",
    "<br>\n",
    "$$ P_{normalizado}(No\\,|\\,Sunny, Cool, High, True) = \\frac{0.0206}{0.0053 + 0.0206}\\times{} 100 = 79.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentarios finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clasificación de ejemplos con valores desconocidos: el atributo con valor desconocido no participa en el producto que sirve para calcular las probabilidades.\n",
    "- Atributos numéricos: se supone que siguen una distribución de probabilidad normal o Gaussiana y se calculan los parámetros $\\mu$ y $\\sigma$ a partir del conjunto de ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Algoritmo Naïve Bayes en Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar las librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es importar las librerías requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB   #Importa clasificador bayesiano\n",
    "\n",
    "\n",
    "# Configuración warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar conjunto de datos del clima\n",
    "data = pd.read_csv(\"DataSets/Clima.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las variables independientes y la variable respuesta\n",
    "X = data.drop('Play', axis=1) #Elimina la última columna, obteniendo las variables independientes\n",
    "y = data['Play'].copy() #Toma la última columna, obteniendo la variable respuesta o dependiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el conjunto test real, simularía la puesta en producción del modelo\n",
    "test_real = pd.read_csv(\"DataSets/Ejemplo.csv\")\n",
    "print(test_real)\n",
    "\n",
    "# Obtener variables independientes\n",
    "test_real = test_real.drop('Play', axis=1) #Elimina la última columna, variable respuesta, se predice con el modelo\n",
    "test_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar subconjuntos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding para Outlook y Humidity. Usamos get_dummies y OneHotEncoder para ver las diferencias.\n",
    "\n",
    "# Codificar 'Outlook' con get_dummies, aplicar sobre train y alinear test\n",
    "\n",
    "X_train_outlook = pd.get_dummies(\n",
    "    X_train[['Outlook']], prefix=\"Out\"\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "X_test_outlook = pd.get_dummies(\n",
    "    X_test[['Outlook']], prefix=\"Out\"\n",
    ").astype(int)\n",
    "\n",
    "test_real_outlook = pd.get_dummies(\n",
    "    test_real[['Outlook']], prefix=\"Out\"\n",
    ").astype(int)\n",
    "\n",
    "# Alinear columnas para que el conjunto de test tenga las mismas que train\n",
    "X_test_outlook = X_test_outlook.reindex(columns=X_train_outlook.columns, fill_value=0)\n",
    "test_real_outlook = test_real_outlook.reindex(columns=X_train_outlook.columns, fill_value=0)\n",
    "\n",
    "# Se puede incorporar el parámetro drop_first=True, lo que hace es eliminar la columna irrelevante, toda la información \n",
    "# se puede en una variable menos que el número de categorías.\n",
    "\n",
    "print(X_train_outlook)\n",
    "print(X_test_outlook)\n",
    "print(test_real_outlook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar 'Humidity' con OneHotEncoder \n",
    "\n",
    "cod_ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "cod_ohe.fit(X_train[['Humidity']])  # Sólo fit con train\n",
    "\n",
    "\n",
    "# Transformar train y test\n",
    "\n",
    "X_train_humidity = pd.DataFrame(\n",
    "    cod_ohe.transform(X_train[['Humidity']]),\n",
    "    columns=cod_ohe.get_feature_names_out(['Humidity']), # Nombres de las columnas codificadas\n",
    "    index=X_train.index\n",
    ").astype(int)\n",
    "\n",
    "X_test_humidity = pd.DataFrame(\n",
    "    cod_ohe.transform(X_test[['Humidity']]),\n",
    "    columns=cod_ohe.get_feature_names_out(['Humidity']), # Nombres de las columnas codificadas\n",
    "    index=X_test.index\n",
    ").astype(int)\n",
    "\n",
    "test_real_humidity = pd.DataFrame(\n",
    "    cod_ohe.transform(test_real[['Humidity']]),\n",
    "    columns=cod_ohe.get_feature_names_out(['Humidity']), # Nombres de las columnas codificadas\n",
    "    index=test_real.index\n",
    ").astype(int)\n",
    "\n",
    "print(X_train_humidity)\n",
    "print(X_test_humidity)\n",
    "print(test_real_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se podría haber usado LabelEncoder al conjunto completo si el modelo no es sensible al orden, como ocurre en un árbol.\n",
    "#data['Humidity'] = OrdinalEncoder(categories=[['normal','high']]).fit_transform(data['Humidity'].values.reshape((-1, 1)))\n",
    "#data['Humidity']\n",
    "\n",
    "# Pero como eso no ocurre para todos los modelos lo hacemos como deberíamos hacerlo en la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación binaria para Windy\n",
    "\n",
    "X_train_windy = X_train[['Windy']].astype(int)\n",
    "X_test_windy = X_test[['Windy']].astype(int)\n",
    "test_real_windy = test_real[['Windy']].astype(int)\n",
    "\n",
    "print(X_train_windy)\n",
    "print(X_test_windy)\n",
    "print(test_real_windy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar 'Temperature' ordinalmente\n",
    "\n",
    "# Una forma sencilla:\n",
    "#temp_map = {'cool': 0, 'mild': 1, 'hot': 2}\n",
    "#X_train_temp = X_train[['Temperature']].replace({'Temperature': temp_map})\n",
    "#X_test_temp = X_test[['Temperature']].replace({'Temperature': temp_map})\n",
    "\n",
    "\n",
    "# Codificar 'Temperature' según el orden: cool < mild < hot\n",
    "encoder_temp = OrdinalEncoder(categories=[['cool', 'mild', 'hot']], handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Codificar sobre train\n",
    "X_train_temp = X_train[['Temperature']].copy()\n",
    "X_train_temp['Temperature'] = encoder_temp.fit_transform(\n",
    "    X_train['Temperature'].values.reshape(-1, 1)\n",
    ").astype(int)\n",
    "\n",
    "# Codificar sobre test usando el mismo encoder (sin refit)\n",
    "X_test_temp = X_test[['Temperature']].copy()\n",
    "X_test_temp['Temperature'] = encoder_temp.transform(\n",
    "    X_test['Temperature'].values.reshape(-1, 1)\n",
    ").astype(int)\n",
    "\n",
    "test_real_temp = test_real[['Temperature']].copy()\n",
    "test_real_temp['Temperature'] = encoder_temp.transform(\n",
    "    test_real['Temperature'].values.reshape(-1, 1)\n",
    ").astype(int)\n",
    "\n",
    "print(X_train_temp)\n",
    "print(X_test_temp)\n",
    "print(test_real_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se codifica también la variable de salida\n",
    "y = LabelEncoder().fit_transform(y.values.reshape((-1, 1)))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todo\n",
    "\n",
    "X_train_final = pd.concat([\n",
    "    X_train_outlook.reset_index(drop=True),\n",
    "    X_train_temp.reset_index(drop=True),\n",
    "    X_train_humidity.reset_index(drop=True),\n",
    "    X_train_windy.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "X_test_final = pd.concat([\n",
    "    X_test_outlook.reset_index(drop=True),\n",
    "    X_test_temp.reset_index(drop=True),\n",
    "    X_test_humidity.reset_index(drop=True),\n",
    "    X_test_windy.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "test_real_final = pd.concat([\n",
    "    test_real_outlook.reset_index(drop=True),\n",
    "    test_real_temp.reset_index(drop=True),\n",
    "    test_real_humidity.reset_index(drop=True),\n",
    "    test_real_windy.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "# Mostrar resultados\n",
    "\n",
    "print(\"X_train codificado:\")\n",
    "print(X_train_final)\n",
    "\n",
    "print(\"\\nX_test codificado:\")\n",
    "print(X_test_final)\n",
    "\n",
    "print(\"\\nX_test codificado:\")\n",
    "print(test_real_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir el modelo NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea el clasificador Naive Bayes, crea un objeto de tipo GaussianNB\n",
    "nbc = GaussianNB()\n",
    "\n",
    "# Realiza el entrenamiento usando el método fit\n",
    "nbc.fit(X_train_final, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observése qué ocurre si se obtiene la precisión sobre el mismo conjunto de entrenamiento\n",
    "score = nbc.score(X_train_final,y_train)\n",
    " \n",
    "print(\"Métrica del modelo para el conjunto de entrenamiento\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir la respuesta sobre un conjunto no usado durante el entrenamiento\n",
    "y_pred = nbc.predict(X_test_final)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los valores de las métricas\n",
    "print('Matriz de confusión: ')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('\\n\\nMétricas de clasificación:')\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizan las métricas obtenidas. Para ello, se observa en la matriz de confusión cuántos valores se han predicho correctamente. \n",
    "\n",
    "También se puede obtener la precisión a partir de las métricas de clasificación. ¿El modelo predijo la mayoría de los datos? ¿Se puede considerar un buen modelo a utilizar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar el modelo usando Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se fija el valor para k-folds\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "scores = cross_val_score(nbc, X_train_final, y_train, cv=kf, scoring=\"accuracy\")\n",
    " \n",
    "print(\"Precisión obtenida para cada iteración de validación cruzada:\", scores)\n",
    " \n",
    "print(\"Media de la precisión obtenida en cada una de las iteraciones de validación cruzada:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred = accuracy_score(y_test, y_pred)\n",
    " \n",
    "print(\"Métrica en el conjunto test:\", score_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Matriz de confusión: ')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('\\n\\nMétricas de clasificación:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizar los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el valor obtenido de la precisión para el conjunto de entrenamiento difiere mucho del obtenido para las observaciones del conjunto de test. Puede estar produciéndose _overfitting_. Si fuera el caso, habría que hacer un reajuste del modelo para evitarlo.\n",
    "\n",
    "En este caso el modelo no está generalizando bien, pero puede ser debido a que existen muy pocos datos en el conjunto de entrenamiento, lo que dificulta mucho el aprendizaje de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificar nuevos ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se alcance unos valores de las métricas que permitan aceptar el modelo como válido y que, por tanto, está listo para su uso, se llevaría a un entorno real y productivo. En esa situación el modelo se enfrentará a datos totalmente desconocidos, que lo simulamos  con los datos almacenados sobre el conjunto test_real, y no se podrá evaluar la respuesta del modelo, salvo las indicaciones que puedan arrojar los expertos en la materia a partir del conocimiento del dominio del problema a resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica el modelo sobre datos desconocidos\n",
    "# Se aplica sobre el conjunto test_real\n",
    "res = nbc.predict(test_real_final)\n",
    "res.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Conclusiones</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha construido un modelo de clasificación con el algoritmo Naïve Bayes en lenguaje de programación Python, en concreto se ha aplicado el tipo Gaussiano. Según este modelo Gaussiano, las características siguen una distribución normal. De esta forma, cuando los predictores tomen valores continuos, en lugar de discretos, el modelo asume que estos valores se muestrean a partir de la distribución gaussiana. \n",
    "\n",
    "El algoritmo Naïve Bayes es un algoritmo de clasificación sencillo y rápido, pero tiene la desventaja de que asume que todas las variables son independientes entre sí, por lo que no podrá aprender la relación existente entre ellas. Esta limitación del algoritmo es necesaria tenerla en cuenta a la hora de aplicarlo, ya que en la vida real es casi imposible obtener un conjunto de características el que las variables sean completamente independientes.\n",
    "\n",
    "\n",
    "\n",
    "A partir del análisis de los resultados se puede observar si se trata de un buen modelo para poder ser utilizado en la resolución del problema planteado. En este ejemplo, en concreto, existen pocos datos, por lo que la precisión de la clasificación no es muy buena.\n",
    "\n",
    "Se pueden comparar los resultados con los obtenidos con los árboles de decisión.¿Difieren los resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\"/> \n",
    "\n",
    "Esta obra está bajo una Licencia Creative Commons Atribución-NoComercial-CompartirIgual 4.0 Internacional.\n",
    "Para ver una copia de esta licencia, véase http://creativecommons.org/licenses/by/4.0/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
